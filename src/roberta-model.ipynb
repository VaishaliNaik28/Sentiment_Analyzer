{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14962339,"datasetId":9577019,"databundleVersionId":15833694}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-25T21:59:53.445533Z","iopub.execute_input":"2026-02-25T21:59:53.446054Z","iopub.status.idle":"2026-02-25T21:59:53.726629Z","shell.execute_reply.started":"2026-02-25T21:59:53.446020Z","shell.execute_reply":"2026-02-25T21:59:53.725836Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/datasets/insha2304/sentiment140-3class-csv/sentiment140_3class.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q -U transformers datasets accelerate evaluate scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T21:59:53.727780Z","iopub.execute_input":"2026-02-25T21:59:53.728189Z","iopub.status.idle":"2026-02-25T21:59:57.996105Z","shell.execute_reply.started":"2026-02-25T21:59:53.728163Z","shell.execute_reply":"2026-02-25T21:59:57.995070Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport transformers\n\nprint(\"Transformers version:\", transformers.__version__)\n\nfrom datasets import Dataset, ClassLabel\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback\n)\n\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:00:11.556852Z","iopub.execute_input":"2026-02-25T22:00:11.557593Z","iopub.status.idle":"2026-02-25T22:00:19.944821Z","shell.execute_reply.started":"2026-02-25T22:00:11.557559Z","shell.execute_reply":"2026-02-25T22:00:19.944208Z"}},"outputs":[{"name":"stdout","text":"Transformers version: 5.2.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/datasets/insha2304/sentiment140-3class-csv/sentiment140_3class.csv\")\n\ndf = df.dropna(subset=[\"text\"])\ndf[\"text\"] = df[\"text\"].astype(str)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:01:04.376244Z","iopub.execute_input":"2026-02-25T22:01:04.377017Z","iopub.status.idle":"2026-02-25T22:01:06.528058Z","shell.execute_reply.started":"2026-02-25T22:01:04.376984Z","shell.execute_reply":"2026-02-25T22:01:06.527399Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  a that s a bummer you shoulda got david carr o...      0\n1  is upset that he can t update his facebook by ...      0\n2  i dived many times for the ball managed to sav...      1\n3     my whole body feels itchy and like its on fire      0\n4  no it s not behaving at all i m mad why am i h...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a that s a bummer you shoulda got david carr o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is upset that he can t update his facebook by ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i dived many times for the ball managed to sav...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>no it s not behaving at all i m mad why am i h...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df = df.sample(n=500000, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:27:17.945659Z","iopub.execute_input":"2026-02-25T22:27:17.946472Z","iopub.status.idle":"2026-02-25T22:27:18.047665Z","shell.execute_reply.started":"2026-02-25T22:27:17.946437Z","shell.execute_reply":"2026-02-25T22:27:18.046715Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)\n\ndataset = dataset.cast_column(\n    \"label\",\n    ClassLabel(num_classes=3)\n)\n\ndataset = dataset.train_test_split(\n    test_size=0.2,\n    stratify_by_column=\"label\"\n)\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:28:01.509330Z","iopub.execute_input":"2026-02-25T22:28:01.509752Z","iopub.status.idle":"2026-02-25T22:28:41.837179Z","shell.execute_reply.started":"2026-02-25T22:28:01.509710Z","shell.execute_reply":"2026-02-25T22:28:41.836520Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a29792bc5e481da65e7e0d50b9f533"}},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', '__index_level_0__'],\n        num_rows: 400000\n    })\n    test: Dataset({\n        features: ['text', 'label', '__index_level_0__'],\n        num_rows: 100000\n    })\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=96\n    )\n\ndataset = dataset.map(tokenize, batched=True)\ndataset = dataset.remove_columns([\"text\"])\ndataset = dataset.with_format(\"torch\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:28:48.255994Z","iopub.execute_input":"2026-02-25T22:28:48.256674Z","iopub.status.idle":"2026-02-25T22:29:35.406078Z","shell.execute_reply.started":"2026-02-25T22:28:48.256641Z","shell.execute_reply":"2026-02-25T22:29:35.401096Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc5166e01e34007aa0e34fe0d911df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd17f4393f7d4d7fb9c854836b0a9384"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a636d1a25a9490b8608b17f72876117"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment\nKey                             | Status     |  | \n--------------------------------+------------+--+-\nroberta.embeddings.position_ids | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    warmup_steps=500,\n    logging_steps=1000,\n    fp16=True,\n    report_to=[]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:39:16.800642Z","iopub.execute_input":"2026-02-25T22:39:16.801420Z","iopub.status.idle":"2026-02-25T22:39:16.840470Z","shell.execute_reply.started":"2026-02-25T22:39:16.801381Z","shell.execute_reply":"2026-02-25T22:39:16.839823Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"print(training_args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:36:56.780641Z","iopub.execute_input":"2026-02-25T22:36:56.781332Z","iopub.status.idle":"2026-02-25T22:36:56.785717Z","shell.execute_reply.started":"2026-02-25T22:36:56.781303Z","shell.execute_reply":"2026-02-25T22:36:56.785045Z"}},"outputs":[{"name":"stdout","text":"TrainingArguments(\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=True,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=2,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\nenable_jit_checkpoint=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=None,\neval_strategy=IntervalStrategy.EPOCH,\neval_use_gather_object=False,\nfp16=True,\nfp16_full_eval=False,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=False,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=None,\nhub_revision=None,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_num_input_tokens_seen=no,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nliger_kernel_config=None,\nload_best_model_at_end=True,\nlocal_rank=-1,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=None,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=1000,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_kwargs=None,\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=loss,\nneftune_noise_alpha=None,\nnum_train_epochs=3,\noptim=OptimizerNames.ADAMW_TORCH_FUSED,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./results,\nparallelism_config=None,\nper_device_eval_batch_size=64,\nper_device_train_batch_size=64,\nprediction_loss_only=False,\nproject=huggingface,\npush_to_hub=False,\nremove_unused_columns=True,\nreport_to=[],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=None,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_steps=500,\nsave_strategy=SaveStrategy.EPOCH,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntrackio_space_id=trackio,\ntrain_sampling_strategy=random,\nuse_cache=False,\nuse_cpu=False,\nuse_liger_kernel=False,\nwarmup_ratio=0.1,\nwarmup_steps=0.1,\nweight_decay=0.01,\n)\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1\": f1_score(labels, predictions, average=\"weighted\")\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:39:22.961026Z","iopub.execute_input":"2026-02-25T22:39:22.961659Z","iopub.status.idle":"2026-02-25T22:39:22.965583Z","shell.execute_reply.started":"2026-02-25T22:39:22.961628Z","shell.execute_reply":"2026-02-25T22:39:22.964726Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:39:25.800793Z","iopub.execute_input":"2026-02-25T22:39:25.801184Z","iopub.status.idle":"2026-02-25T22:39:25.816472Z","shell.execute_reply.started":"2026-02-25T22:39:25.801157Z","shell.execute_reply":"2026-02-25T22:39:25.815909Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T22:39:29.170496Z","iopub.execute_input":"2026-02-25T22:39:29.170801Z","iopub.status.idle":"2026-02-26T02:26:18.409280Z","shell.execute_reply.started":"2026-02-25T22:39:29.170772Z","shell.execute_reply":"2026-02-26T02:26:18.408607Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [18750/18750 3:46:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.048986</td>\n      <td>0.992258</td>\n      <td>0.795440</td>\n      <td>0.794739</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.878655</td>\n      <td>0.914827</td>\n      <td>0.817970</td>\n      <td>0.818344</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.749381</td>\n      <td>0.921680</td>\n      <td>0.822560</td>\n      <td>0.822391</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027459f3cb1841b493adaa321bfa47e2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b6f0c8277c48b38b23bbcf37e8d58d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9623fb95d654187b4e4019532b487c6"}},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias'].\nThere were unexpected keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.beta', 'roberta.embeddings.LayerNorm.gamma', 'roberta.encoder.layer.0.attention.output.LayerNorm.beta', 'roberta.encoder.layer.0.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.0.output.LayerNorm.beta', 'roberta.encoder.layer.0.output.LayerNorm.gamma', 'roberta.encoder.layer.1.attention.output.LayerNorm.beta', 'roberta.encoder.layer.1.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.1.output.LayerNorm.beta', 'roberta.encoder.layer.1.output.LayerNorm.gamma', 'roberta.encoder.layer.2.attention.output.LayerNorm.beta', 'roberta.encoder.layer.2.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.2.output.LayerNorm.beta', 'roberta.encoder.layer.2.output.LayerNorm.gamma', 'roberta.encoder.layer.3.attention.output.LayerNorm.beta', 'roberta.encoder.layer.3.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.3.output.LayerNorm.beta', 'roberta.encoder.layer.3.output.LayerNorm.gamma', 'roberta.encoder.layer.4.attention.output.LayerNorm.beta', 'roberta.encoder.layer.4.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.4.output.LayerNorm.beta', 'roberta.encoder.layer.4.output.LayerNorm.gamma', 'roberta.encoder.layer.5.attention.output.LayerNorm.beta', 'roberta.encoder.layer.5.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.5.output.LayerNorm.beta', 'roberta.encoder.layer.5.output.LayerNorm.gamma', 'roberta.encoder.layer.6.attention.output.LayerNorm.beta', 'roberta.encoder.layer.6.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.6.output.LayerNorm.beta', 'roberta.encoder.layer.6.output.LayerNorm.gamma', 'roberta.encoder.layer.7.attention.output.LayerNorm.beta', 'roberta.encoder.layer.7.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.7.output.LayerNorm.beta', 'roberta.encoder.layer.7.output.LayerNorm.gamma', 'roberta.encoder.layer.8.attention.output.LayerNorm.beta', 'roberta.encoder.layer.8.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.8.output.LayerNorm.beta', 'roberta.encoder.layer.8.output.LayerNorm.gamma', 'roberta.encoder.layer.9.attention.output.LayerNorm.beta', 'roberta.encoder.layer.9.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.9.output.LayerNorm.beta', 'roberta.encoder.layer.9.output.LayerNorm.gamma', 'roberta.encoder.layer.10.attention.output.LayerNorm.beta', 'roberta.encoder.layer.10.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.10.output.LayerNorm.beta', 'roberta.encoder.layer.10.output.LayerNorm.gamma', 'roberta.encoder.layer.11.attention.output.LayerNorm.beta', 'roberta.encoder.layer.11.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.11.output.LayerNorm.beta', 'roberta.encoder.layer.11.output.LayerNorm.gamma'].\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=18750, training_loss=0.93593283203125, metrics={'train_runtime': 13608.5002, 'train_samples_per_second': 88.18, 'train_steps_per_second': 1.378, 'total_flos': 5.92005189888e+16, 'train_loss': 0.93593283203125, 'epoch': 3.0})"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T03:15:34.310672Z","iopub.execute_input":"2026-02-26T03:15:34.311329Z","iopub.status.idle":"2026-02-26T03:15:46.404465Z","shell.execute_reply.started":"2026-02-26T03:15:34.311298Z","shell.execute_reply":"2026-02-26T03:15:46.403579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   18/18750 00:10 < 3:24:37, 1.53 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_390/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m                     ):\n\u001b[1;32m   1749\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":59}]}